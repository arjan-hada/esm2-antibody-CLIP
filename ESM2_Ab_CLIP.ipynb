{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "toc_visible": true,
      "collapsed_sections": [
        "aZPIm2kP49Yh",
        "C-VDB6wGK7b0",
        "2jZrIQOdLQJz"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNTeZhpx0qIwaD+5JLLsIw5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcee5d170ca3442886391808562ee76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_38c2c335c2574631a8a6ac89d0e7d986",
              "IPY_MODEL_bd358687c2914e9ea2e8d6459fddc909",
              "IPY_MODEL_9b98bbbdd9284588a3fc2a7f1f0d1bcf",
              "IPY_MODEL_2e0d9fb75dd74f318702bc39850c3770"
            ],
            "layout": "IPY_MODEL_c0b1de6cb63043d59931aacf15fa4da2"
          }
        },
        "276b17bc52bd4a91ac293a87724c1fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98a7334af49942e590327cfe309ab15a",
            "placeholder": "​",
            "style": "IPY_MODEL_3f247c3d5e8b4fc9bf9308c3ab7a6e40",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "dacc0643df234a95b7e8d92de56d10b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_1e484527b71a4f7e80b7a7f439b13568",
            "placeholder": "​",
            "style": "IPY_MODEL_e1406578361d4b7c9ef3e048552df5a0",
            "value": ""
          }
        },
        "d8fae74b58784a248a8def51e583076f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_08aec34825b240bf815020770692bb15",
            "style": "IPY_MODEL_7d5ad68ae5fc47edbf41ab422146ef87",
            "value": true
          }
        },
        "1318853ee61e4ad8be67346fb37d72b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_2ab4b604050446ea97b981cbe516095a",
            "style": "IPY_MODEL_fc1c35e1db3c40fc8d709f199306169e",
            "tooltip": ""
          }
        },
        "94b79f35b9a44344ad5c4d6eb096fff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51136a2445014772beaae86e3196259e",
            "placeholder": "​",
            "style": "IPY_MODEL_b06568dd7cf841e8aa357574a89b360b",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "c0b1de6cb63043d59931aacf15fa4da2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "98a7334af49942e590327cfe309ab15a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f247c3d5e8b4fc9bf9308c3ab7a6e40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e484527b71a4f7e80b7a7f439b13568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1406578361d4b7c9ef3e048552df5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08aec34825b240bf815020770692bb15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d5ad68ae5fc47edbf41ab422146ef87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ab4b604050446ea97b981cbe516095a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc1c35e1db3c40fc8d709f199306169e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "51136a2445014772beaae86e3196259e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b06568dd7cf841e8aa357574a89b360b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69f4689fd5db435d902648c2ae18ffff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7f6c4dedbf4b22a873e913f55786eb",
            "placeholder": "​",
            "style": "IPY_MODEL_956e699c2ee5402a845e6389b60a4c46",
            "value": "Connecting..."
          }
        },
        "2f7f6c4dedbf4b22a873e913f55786eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956e699c2ee5402a845e6389b60a4c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38c2c335c2574631a8a6ac89d0e7d986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e38429157d7f4b299af5c1dbf1008778",
            "placeholder": "​",
            "style": "IPY_MODEL_4c9abab98c2a4f7fb8458299c641a927",
            "value": "Token is valid (permission: write)."
          }
        },
        "bd358687c2914e9ea2e8d6459fddc909": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ae6d7f5ef94d908f93444dbcbbeac6",
            "placeholder": "​",
            "style": "IPY_MODEL_8a38f032702c4d5d88cf0a02d97ad9c2",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "9b98bbbdd9284588a3fc2a7f1f0d1bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a41db0e37e3439394c26ff1a370e556",
            "placeholder": "​",
            "style": "IPY_MODEL_e8fe15985ead4cf289069dc6085e0216",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "2e0d9fb75dd74f318702bc39850c3770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d497e0d33254b3a9cbe8af815a1f4b8",
            "placeholder": "​",
            "style": "IPY_MODEL_6b83e9144e964a1b977e73cab5270e94",
            "value": "Login successful"
          }
        },
        "e38429157d7f4b299af5c1dbf1008778": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c9abab98c2a4f7fb8458299c641a927": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87ae6d7f5ef94d908f93444dbcbbeac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a38f032702c4d5d88cf0a02d97ad9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a41db0e37e3439394c26ff1a370e556": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8fe15985ead4cf289069dc6085e0216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5d497e0d33254b3a9cbe8af815a1f4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b83e9144e964a1b977e73cab5270e94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arjan-hada/esm2-antibody-CLIP/blob/main/ESM2_Ab_CLIP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ESM2AbCLIP: Antibody structure aware ESM2 model"
      ],
      "metadata": {
        "id": "JKV_0K5QjIzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "p9vnHkEAfBEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers accelerate &> /dev/null"
      ],
      "metadata": {
        "id": "LNeTW6Psdk5X"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dRmIE_RscmwF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "path = Path(\"/content/gdrive/\")\n",
        "path_data = Path(\"/content/gdrive/MyDrive/data/proteinflow_esmif1_20240520-0899946\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rEc9sdfnxl0",
        "outputId": "c518c69e-24c6-42d8-fd40-f9565de92fa3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "QSt2dK7xfENn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class AntibodyDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Initialize the dataset.\n",
        "\n",
        "    Args:\n",
        "        data_path (str): Path to the pickle file containing data.\n",
        "        tokenizer (transformers.PreTrainedTokenizer): Tokenizer to process the sequences.\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path, tokenizer):\n",
        "        self.data = pd.read_pickle(data_path)\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get item by index.\n",
        "        \"\"\"\n",
        "        row = self.data.iloc[idx]\n",
        "        sequence = row['sequence']\n",
        "        embedding = torch.tensor(row['embedding'], dtype=torch.float32)\n",
        "\n",
        "        inputs = self.tokenizer(sequence, return_tensors='pt', padding=False,\n",
        "                                truncation=False)\n",
        "\n",
        "        return {\n",
        "            'input_ids': inputs['input_ids'].squeeze(),\n",
        "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
        "            'labels': embedding\n",
        "        }"
      ],
      "metadata": {
        "id": "z5HILn0wrDbI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github copilot: The conversion of row['embedding'] to a tensor is done directly within __getitem__. This is generally fine, but if the dataset is large and this operation is costly, consider pre-processing steps or caching mechanisms."
      ],
      "metadata": {
        "id": "dMXygkMChCcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Initialize tokenizer\n",
        "model_ckpt = 'facebook/esm2_t33_650M_UR50D'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# Initialize datasets\n",
        "train_ds = AntibodyDataset(path_data/'train_data.pkl', tokenizer)\n",
        "valid_ds = AntibodyDataset(path_data/'valid_data.pkl', tokenizer)\n",
        "test_ds = AntibodyDataset(path_data/'test_data.pkl', tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U_HhYHiufRo",
        "outputId": "e2de5898-0d56-4e56-c6d7-07ed6c337a26"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DataCollator\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "# Initialize DataLoader with DataCollator\n",
        "batch_size=2\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=False, collate_fn=data_collator)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=False, collate_fn=data_collator)"
      ],
      "metadata": {
        "id": "QXiExMh5hYpa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dl))\n",
        "print(batch)\n",
        "print(batch['input_ids'].shape)\n",
        "print(batch['attention_mask'].shape)\n",
        "print(batch['labels'].shape)"
      ],
      "metadata": {
        "id": "N_0Y45PQuidt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f28eb7-4053-4a49-8687-33ab669575f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[ 0, 13, 14,  ...,  1,  1,  1],\n",
            "        [ 0,  9, 17,  ...,  7, 12,  2]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
            "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[-0.0578, -0.0622, -0.1321,  ...,  0.2488, -0.0769,  0.2094],\n",
            "        [-0.0398,  0.1967, -0.0542,  ...,  0.0323, -0.0520,  0.1241]])}\n",
            "torch.Size([2, 700])\n",
            "torch.Size([2, 700])\n",
            "torch.Size([2, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Model for Contrastive Pre-training"
      ],
      "metadata": {
        "id": "aZPIm2kP49Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer, PreTrainedModel, PretrainedConfig\n",
        "from torch.cuda.amp import autocast\n",
        "\n",
        "class ESM2AbCLIPConfig(PretrainedConfig):\n",
        "    model_type = \"esm2_ab_clip\"\n",
        "\n",
        "    def __init__(self, projection_dim=512,\n",
        "                 model_ckpt='facebook/esm2_t33_650M_UR50D',\n",
        "                 **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.projection_dim = projection_dim\n",
        "        self.model_ckpt = model_ckpt\n",
        "\n",
        "class ESM2AbCLIP(PreTrainedModel):\n",
        "    config_class = ESM2AbCLIPConfig\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.sequence_model = AutoModel.from_pretrained(config.model_ckpt)\n",
        "\n",
        "        # Projection layers for sequence embeddings with GeLU\n",
        "        self.sequence_projection = nn.Sequential(\n",
        "            nn.Linear(self.sequence_model.config.hidden_size, config.projection_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # Projection layer for structure embeddings with GeLU\n",
        "        self.structure_projection = nn.Sequential(\n",
        "            nn.Linear(config.projection_dim, config.projection_dim),\n",
        "            nn.GELU()\n",
        "        )\n",
        "\n",
        "        # Learnable temperature parameter\n",
        "        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))\n",
        "\n",
        "        # Load and initialize weights\n",
        "        self.post_init()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        with autocast():  # Enable mixed-precision for the forward pass\n",
        "            # Forward pass through the sequence model\n",
        "            outputs = self.sequence_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            cls_hidden_state = outputs.last_hidden_state[:, 0, :]  # [CLS] token pooling\n",
        "\n",
        "            # Project the sequence embeddings\n",
        "            projected_sequence = self.sequence_projection(cls_hidden_state)\n",
        "            projected_structure = self.structure_projection(labels)\n",
        "\n",
        "            # Clamp the logit scale value to ensure it does not exceed log(100)\n",
        "            self.logit_scale.data.clamp_(max=np.log(100.0))\n",
        "\n",
        "            return {\n",
        "                'logits': (projected_sequence, projected_structure)\n",
        "            }"
      ],
      "metadata": {
        "id": "_IVxy82krSQm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = ESM2AbCLIPConfig(projection_dim=512,\n",
        "                                model_ckpt='facebook/esm2_t6_8M_UR50D')\n",
        "model = ESM2AbCLIP(model_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16E7DE51h56d",
        "outputId": "28dd438f-1ba7-4aea-d709-bbd4085836f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.forward(**batch)\n",
        "logits = outputs['logits']\n",
        "print(logits[0].shape)\n",
        "print(logits[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIum7Cv4h_Um",
        "outputId": "b5e6aac8-d434-4a72-b6e1-8b8b6c9000e2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 512])\n",
            "torch.Size([2, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contrastive Loss"
      ],
      "metadata": {
        "id": "C-VDB6wGK7b0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaled pairwise cosine similarities are a crucial component in many contrastive learning frameworks, including CLIP (Contrastive Language-Image Pre-training).\n",
        "\n",
        "**Cosine similarity** measures the cosine of the angle between two vectors in an inner product space. It is a measure of similarity between two non-zero vectors, giving a value between -1 and 1.\n",
        "\n",
        "For two vectors \\( A \\) and \\( B \\):\n",
        "$$ \\text{cosine_similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} $$\n",
        "\n",
        "In PyTorch, cosine similarity between two sets of embeddings can be computed using:\n",
        "```python\n",
        "import torch.nn.functional as F\n",
        "\n",
        "cos_sim = F.cosine_similarity(embedding1, embedding2, dim=-1)\n",
        "```\n",
        "\n",
        "**Pairwise cosine similarity** computes the cosine similarity between each pair of vectors from two sets of vectors. This is useful in comparing all possible pairs in a batch.\n",
        "\n",
        "For sequence embeddings $ \\text{seq_embeddings} $ and structure embeddings $ \\text{struct_embeddings}$:\n",
        "\n",
        "```python\n",
        "cos_sim_matrix = torch.mm(seq_embeddings, struct_embeddings.t())\n",
        "```\n",
        "\n",
        "This gives a matrix of cosine similarities between each sequence and each structure embedding."
      ],
      "metadata": {
        "id": "SJO6kdThhfQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "\n",
        "    def forward(self, seq_embeddings, struct_embeddings, logit_scale):\n",
        "        # Normalize embeddings to unit vectors\n",
        "        seq_embeddings = F.normalize(seq_embeddings, dim=1)\n",
        "        struct_embeddings = F.normalize(struct_embeddings, dim=1)\n",
        "\n",
        "        # Compute pairwise cosine similarities and scale with temperature\n",
        "        temperature = torch.exp(logit_scale)\n",
        "        logits_per_seq = torch.mm(seq_embeddings, struct_embeddings.t()) * temperature\n",
        "        logits_per_struct = logits_per_seq.t()\n",
        "\n",
        "        # Labels for contrastive loss\n",
        "        labels = torch.arange(seq_embeddings.size(0)).to(seq_embeddings.device)\n",
        "\n",
        "        # Contrastive loss as described in the paper\n",
        "        loss_seq = F.cross_entropy(logits_per_seq, labels)\n",
        "        loss_struct = F.cross_entropy(logits_per_struct, labels)\n",
        "        loss = (loss_seq + loss_struct) / 2\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "cwXnSpxsLDZo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ContrastiveLoss` class is designed to implement a contrastive learning objective for sequence and structure embeddings, similar to how CLIP (Contrastive Language-Image Pre-training) works. The goal is to bring corresponding sequence and structure embeddings closer in the embedding space while pushing non-corresponding pairs further apart.\n",
        "\n",
        "#### Key Components\n",
        "\n",
        "1. **Normalization**: Both sequence and structure embeddings are normalized to unit vectors. This ensures that the cosine similarity is computed correctly.\n",
        "   \n",
        "2. **Cosine Similarity**: The similarity between the embeddings is computed using the dot product. The temperature parameter τ is used to scale the logits (cosine similarities) before applying the softmax function in contrastive learning. It controls the sharpness of the distribution:\n",
        "    - High temperature (large τ) results in a smoother probability distribution.\n",
        "    - Low temperature (small τ) results in a sharper distribution.\n",
        "\n",
        "    Making τ a learnable parameter allows the model to adapt the scaling dynamically based on the data and the training process.\n",
        "\n",
        "   \n",
        "3. **Contrastive Loss**:\n",
        "   - **Sequence-to-Structure**: Each sequence embedding is compared against all structure embeddings. The goal is to maximize the similarity with its corresponding structure embedding and minimize the similarity with others.\n",
        "   - **Structure-to-Sequence**: Similarly, each structure embedding is compared against all sequence embeddings.\n",
        "\n",
        "4. **Cross-Entropy Loss**: The loss is computed using cross-entropy, treating the problem as a classification task where the correct pair should have the highest similarity score."
      ],
      "metadata": {
        "id": "fkl5NqNiLHO4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The computation of temperature = torch.exp(logit_scale) could potentially lead to numerical instability if logit_scale is large. There is a clamp (torch.clamp(logit_scale, max=...)) in model def to ensure stability."
      ],
      "metadata": {
        "id": "L9Dri0wLiLmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fct = ContrastiveLoss()  # Instantiate the loss function\n",
        "loss = loss_fct(logits[0], logits[1], model.logit_scale)  # Compute the loss\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiN5B4J1ialV",
        "outputId": "3817df72-c07a-47dc-cdf8-34b758050a7c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6715, grad_fn=<DivBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Performance measures"
      ],
      "metadata": {
        "id": "oMrWY06_1_z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will implement the Alignment and Uniformity metrics as proposed by [Wang & Isola (2020)](https://arxiv.org/abs/2005.10242), in addition to Contrastive Accuracy and Top-K Accuracy.\n",
        "\n",
        "1. **Alignment** measures how close positive pairs are in the embedding space.\n",
        "\n",
        "  $$\n",
        "  \\text{Alignment} = \\mathbb{E}_{(x, y) \\sim p_{\\text{pos}}} \\left[ \\| f(x) - f(y) \\|^2 \\right]\n",
        "  $$\n",
        "  This is calculated as the average squared Euclidean distance between embeddings of positive pairs. A good alignment score is close to 0, indicating that positive pairs are nearly identical in the embedding space.\n",
        "\n",
        "\n",
        "2. **Uniformity** measures how uniformly the embeddings are spread on the unit hypersphere.\n",
        "  $$\n",
        "  \\text{Uniformity} = \\log \\mathbb{E}_{(x, y) \\sim p_{\\text{data}}} \\left[ e^{-2 \\| f(x) - f(y) \\|^2} \\right]\n",
        "  $$\n",
        "  This is calculated as the logarithm of the expected exponential of the negative squared Euclidean distance between all pairs of embeddings. High Uniformity indicates that embeddings are well spread out uniformly across the embedding space, which is desirable.\n",
        "\n",
        "3. **Cosine Similarity** measures the cosine of the angle between two non-zero vectors.\n",
        "\n",
        "4. **Contrastive Accuracy** measures how often the model correctly identifies the matching pair among a set of negatives.\n",
        "\n",
        "5. **Top-K Accuracy** measures whether the true positive is within the top K closest predictions.\n"
      ],
      "metadata": {
        "id": "ScRlWnZeZcjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Function to compute the Alignment metric\n",
        "def compute_alignment(seq_embeddings, struct_embeddings):\n",
        "    distances = (seq_embeddings - struct_embeddings).pow(2).sum(dim=1)\n",
        "    alignment = distances.mean().item()\n",
        "    return alignment\n",
        "\n",
        "# Function to compute the Uniformity metric\n",
        "# This function is computationally intensive and may take a while to run\n",
        "def compute_uniformity(embeddings):\n",
        "    pairwise_distances = torch.cdist(embeddings, embeddings, p=2).pow(2)\n",
        "    uniformity = torch.log(torch.exp(-2 * pairwise_distances).mean()).item()\n",
        "    return uniformity\n",
        "\n",
        "# Function to compute the Cosine Similarity metric\n",
        "def compute_cosine_similarity(seq_embeddings, struct_embeddings):\n",
        "    \"\"\"\n",
        "    This function normalizes the sequence and structure embeddings to unit\n",
        "    vectors and then computes the cosine similarity between each pair using\n",
        "    matrix multiplication.\n",
        "    \"\"\"\n",
        "    cosine_sim = torch.mm(seq_embeddings, struct_embeddings.t())\n",
        "    return cosine_sim\n",
        "\n",
        "# Function to compute the Contrastive Accuracy\n",
        "def compute_contrastive_accuracy(cosine_sim):\n",
        "    \"\"\"\n",
        "    This function finds the index of the maximum cosine similarity for each\n",
        "    sequence embedding and compares it to the correct index.\n",
        "    It then computes the mean accuracy.\n",
        "    \"\"\"\n",
        "    correct_preds = cosine_sim.argmax(dim=1)\n",
        "    correct = correct_preds == torch.arange(cosine_sim.size(0)).to(cosine_sim)\n",
        "    return correct.float().mean().item()\n",
        "\n",
        "# Function to compute the Top-K Accuracy\n",
        "def compute_top_k_accuracy(cosine_sim, k=1):\n",
        "    \"\"\"\n",
        "    This function finds the top K predictions for each sequence embedding and\n",
        "    checks if the correct match is within these top K predictions.\n",
        "    It then computes the mean accuracy.\n",
        "    \"\"\"\n",
        "    top_k_preds = cosine_sim.topk(k, dim=1)[1]\n",
        "    correct = torch.arange(cosine_sim.size(0)).unsqueeze(1).expand_as(top_k_preds)\n",
        "    correct = correct == top_k_preds\n",
        "    return correct.any(dim=1).float().mean().item()"
      ],
      "metadata": {
        "id": "9C7pAxJ42FUh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    seq_embeddings, struct_embeddings = eval_pred.predictions\n",
        "    seq_embeddings = torch.tensor(seq_embeddings)\n",
        "    struct_embeddings = torch.tensor(struct_embeddings)\n",
        "\n",
        "    # Normalize embeddings\n",
        "    seq_embeddings = F.normalize(seq_embeddings, dim=1)\n",
        "    struct_embeddings = F.normalize(struct_embeddings, dim=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    alignment = compute_alignment(seq_embeddings, struct_embeddings)\n",
        "    combined_embeddings = torch.cat((seq_embeddings, struct_embeddings), dim=0)\n",
        "    uniformity = compute_uniformity(combined_embeddings)\n",
        "    cosine_sim = compute_cosine_similarity(seq_embeddings, struct_embeddings)\n",
        "    contrastive_accuracy = compute_contrastive_accuracy(cosine_sim)\n",
        "    top_5_accuracy = compute_top_k_accuracy(cosine_sim, k=5)\n",
        "    top_10_accuracy = compute_top_k_accuracy(cosine_sim, k=10)\n",
        "\n",
        "    metrics = {\n",
        "        \"alignment\": alignment,\n",
        "        \"uniformity\": uniformity,\n",
        "        \"contrastive_accuracy\": contrastive_accuracy,\n",
        "        \"top_5_accuracy\": top_5_accuracy,\n",
        "        \"top_10_accuracy\": top_10_accuracy\n",
        "    }\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "n2HO0TZ72UMh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "seq_embeddings, struct_embeddings = logits[0], logits[1]\n",
        "seq_embeddings = F.normalize(seq_embeddings, dim=1)\n",
        "struct_embeddings = F.normalize(struct_embeddings, dim=1)\n",
        "\n",
        "alignment = compute_alignment(seq_embeddings, struct_embeddings)\n",
        "combined_embeddings = torch.cat((seq_embeddings, struct_embeddings), dim=0)\n",
        "uniformity = compute_uniformity(combined_embeddings)\n",
        "cosine_sim = compute_cosine_similarity(seq_embeddings, struct_embeddings)\n",
        "contrastive_accuracy = compute_contrastive_accuracy(cosine_sim)\n",
        "top_1_accuracy = compute_top_k_accuracy(cosine_sim, k=1)\n",
        "\n",
        "# Print the results\n",
        "print(\"Contrastive Loss:\", loss.item())\n",
        "print(\"Alignment:\", alignment)\n",
        "print(\"Uniformity:\", uniformity)\n",
        "print(\"Contrastive Accuracy:\", contrastive_accuracy)\n",
        "print(\"Top-1 Accuracy:\", top_1_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaKpWt5Wiqcu",
        "outputId": "fe162dea-4929-418e-cdc2-8b268050d6e2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contrastive Loss: 0.6715006232261658\n",
            "Alignment: 2.0915002822875977\n",
            "Uniformity: -0.947462797164917\n",
            "Contrastive Accuracy: 0.5\n",
            "Top-1 Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Trainer for Contrastive Learning"
      ],
      "metadata": {
        "id": "2jZrIQOdLQJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "class ContrastiveTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        outputs = model(**inputs)  # Forward pass to get logits\n",
        "        logits = outputs['logits']\n",
        "\n",
        "        # Access logit_scale from the underlying model\n",
        "        logit_scale = model.module.logit_scale if hasattr(model, 'module') else model.logit_scale\n",
        "\n",
        "        loss_fct = ContrastiveLoss()  # Instantiate the loss function\n",
        "        loss = loss_fct(logits[0], logits[1], model.logit_scale)  # Compute the loss\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss"
      ],
      "metadata": {
        "id": "Y_1syrTL-HRa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc # Python's garbage collection module\n",
        "\n",
        "def clear_memory():\n",
        "    gc.collect() # explicitly triggers garbage collection, free up memory\n",
        "    if torch.cuda.is_available(): torch.cuda.empty_cache() # clears the PyTorch CUDA memory cache"
      ],
      "metadata": {
        "id": "sGSBJE0dgpV6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "_VKFpaebvaea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original CLIP parameters from **Learning Transferable Visual Models From Natural Language Supervision**\n",
        "original_dataset_size = 400 * 10**6  # 400 million pairs\n",
        "original_batch_size = 32768\n",
        "original_epochs = 32\n",
        "original_warmup_steps = 2000\n",
        "\n",
        "# Calculate total training steps for the original setup\n",
        "original_total_training_steps = (original_dataset_size * original_epochs) / original_batch_size\n",
        "\n",
        "# Calculate the warmup ratio\n",
        "original_warmup_ratio = original_warmup_steps / original_total_training_steps\n",
        "\n",
        "print(f\"Original total training steps: {original_total_training_steps}\")\n",
        "print(f\"Original warmup ratio: {original_warmup_ratio}\")\n",
        "\n",
        "# Your training setup parameters\n",
        "our_dataset_size = 1571  # Your dataset size\n",
        "our_batch_size = 8\n",
        "our_epochs = 5\n",
        "\n",
        "# Calculate total training steps for your setup\n",
        "our_total_training_steps = (our_dataset_size * our_epochs) / our_batch_size\n",
        "\n",
        "# Calculate your warmup steps using the original warmup ratio\n",
        "our_warmup_steps = int(original_warmup_ratio * our_total_training_steps)\n",
        "our_warmup_steps = max(1, our_warmup_steps)  # Ensure at least 1 warmup step\n",
        "\n",
        "print(f\"Our total training steps: {our_total_training_steps}\")\n",
        "print(f\"Our warmup steps: {our_warmup_steps}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guh0OeGCyW1c",
        "outputId": "ea1d18cf-ce31-4aed-ff7e-cd98d7fed24b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original total training steps: 390625.0\n",
            "Original warmup ratio: 0.00512\n",
            "Our total training steps: 981.875\n",
            "Our warmup steps: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "num_epochs = 5\n",
        "batch_size = 8\n",
        "logging_steps = len(train_ds) // batch_size\n",
        "model_name = f\"{model_ckpt}-Ab-CLIP-v0\"\n",
        "\n",
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name,\n",
        "    num_train_epochs=num_epochs,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=1e-4,\n",
        "    weight_decay=0.25,\n",
        "    adam_beta1=0.9,\n",
        "    adam_beta2=0.98,\n",
        "    adam_epsilon=1e-6,\n",
        "    fp16=True, # Mixed-precision training\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=3, # for stability during the initial phase of training\n",
        "    load_best_model_at_end=True,\n",
        "    disable_tqdm=False,\n",
        "    logging_steps=logging_steps,\n",
        "    evaluation_strategy=\"epoch\",  # Evaluate at the end of each epoch\n",
        "    save_strategy=\"epoch\",  # Save the model at the end of each epoch\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3d_jF8o-5mR",
        "outputId": "c386efa4-e099-4e55-b73a-8ee6ba3365d6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1474: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To share your model with the community\n",
        "# First store your authentication token from the Hugging Face website and then execute this cell\n",
        "# Make sure to get token with WRITE access\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "dcee5d170ca3442886391808562ee76b",
            "276b17bc52bd4a91ac293a87724c1fe2",
            "dacc0643df234a95b7e8d92de56d10b3",
            "d8fae74b58784a248a8def51e583076f",
            "1318853ee61e4ad8be67346fb37d72b2",
            "94b79f35b9a44344ad5c4d6eb096fff7",
            "c0b1de6cb63043d59931aacf15fa4da2",
            "98a7334af49942e590327cfe309ab15a",
            "3f247c3d5e8b4fc9bf9308c3ab7a6e40",
            "1e484527b71a4f7e80b7a7f439b13568",
            "e1406578361d4b7c9ef3e048552df5a0",
            "08aec34825b240bf815020770692bb15",
            "7d5ad68ae5fc47edbf41ab422146ef87",
            "2ab4b604050446ea97b981cbe516095a",
            "fc1c35e1db3c40fc8d709f199306169e",
            "51136a2445014772beaae86e3196259e",
            "b06568dd7cf841e8aa357574a89b360b",
            "69f4689fd5db435d902648c2ae18ffff",
            "2f7f6c4dedbf4b22a873e913f55786eb",
            "956e699c2ee5402a845e6389b60a4c46",
            "38c2c335c2574631a8a6ac89d0e7d986",
            "bd358687c2914e9ea2e8d6459fddc909",
            "9b98bbbdd9284588a3fc2a7f1f0d1bcf",
            "2e0d9fb75dd74f318702bc39850c3770",
            "e38429157d7f4b299af5c1dbf1008778",
            "4c9abab98c2a4f7fb8458299c641a927",
            "87ae6d7f5ef94d908f93444dbcbbeac6",
            "8a38f032702c4d5d88cf0a02d97ad9c2",
            "2a41db0e37e3439394c26ff1a370e556",
            "e8fe15985ead4cf289069dc6085e0216",
            "5d497e0d33254b3a9cbe8af815a1f4b8",
            "6b83e9144e964a1b977e73cab5270e94"
          ]
        },
        "id": "dBREIUIbUOex",
        "outputId": "e2073f6d-9443-4a00-8d5c-e266674fd8d4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcee5d170ca3442886391808562ee76b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model with custom configuration\n",
        "model_config = ESM2AbCLIPConfig(projection_dim=512,\n",
        "                                model_ckpt='facebook/esm2_t6_8M_UR50D')\n",
        "model = ESM2AbCLIP(model_config)\n",
        "\n",
        "# Initialize DataCollator\n",
        "data_collator = DataCollatorWithPadding(tokenizer)\n",
        "\n",
        "trainer = ContrastiveTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=valid_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkAtLqumUPph",
        "outputId": "1ac3f0ba-d1ce-4d4e-9f45-eee25f1b9283"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally set the max_split_size_mb to avoid fragmentation issues\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'"
      ],
      "metadata": {
        "id": "BKm5LG4WnhaK"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clear_memory()\n",
        "# Train the model\n",
        "print(torch.cuda.memory_summary())\n",
        "trainer.train()\n",
        "print(torch.cuda.memory_summary())\n",
        "trainer.push_to_hub(commit_message=\"Training completed!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rQCyQOlTuKFw",
        "outputId": "8c838d14-84bd-4767-c040-2335bea5e3c0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  32320 KiB |  32320 KiB |  32320 KiB |      0 B   |\n",
            "|       from large pool |  20482 KiB |  20482 KiB |  20482 KiB |      0 B   |\n",
            "|       from small pool |  11838 KiB |  11838 KiB |  11838 KiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  32320 KiB |  32320 KiB |  32320 KiB |      0 B   |\n",
            "|       from large pool |  20482 KiB |  20482 KiB |  20482 KiB |      0 B   |\n",
            "|       from small pool |  11838 KiB |  11838 KiB |  11838 KiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |  32301 KiB |  32301 KiB |  32301 KiB |      0 B   |\n",
            "|       from large pool |  20482 KiB |  20482 KiB |  20482 KiB |      0 B   |\n",
            "|       from small pool |  11819 KiB |  11819 KiB |  11819 KiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  55296 KiB |  55296 KiB |  55296 KiB |      0 B   |\n",
            "|       from large pool |  40960 KiB |  40960 KiB |  40960 KiB |      0 B   |\n",
            "|       from small pool |  14336 KiB |  14336 KiB |  14336 KiB |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  22975 KiB |  22978 KiB |  49348 KiB |  26372 KiB |\n",
            "|       from large pool |  20477 KiB |  20477 KiB |  38077 KiB |  17600 KiB |\n",
            "|       from small pool |   2498 KiB |   2500 KiB |  11270 KiB |   8772 KiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     116    |     116    |     116    |       0    |\n",
            "|       from large pool |      13    |      13    |      13    |       0    |\n",
            "|       from small pool |     103    |     103    |     103    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     116    |     116    |     116    |       0    |\n",
            "|       from large pool |      13    |      13    |      13    |       0    |\n",
            "|       from small pool |     103    |     103    |     103    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       9    |       9    |       9    |       0    |\n",
            "|       from large pool |       2    |       2    |       2    |       0    |\n",
            "|       from small pool |       7    |       7    |       7    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       8    |       8    |       9    |       1    |\n",
            "|       from large pool |       2    |       2    |       2    |       0    |\n",
            "|       from small pool |       6    |       6    |       7    |       1    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='980' max='980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [980/980 08:19, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Alignment</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Contrastive Accuracy</th>\n",
              "      <th>Top 5 Accuracy</th>\n",
              "      <th>Top 10 Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.079100</td>\n",
              "      <td>1.242567</td>\n",
              "      <td>1.203027</td>\n",
              "      <td>-2.381756</td>\n",
              "      <td>0.068027</td>\n",
              "      <td>0.306122</td>\n",
              "      <td>0.469388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.483300</td>\n",
              "      <td>1.138185</td>\n",
              "      <td>1.207227</td>\n",
              "      <td>-2.768368</td>\n",
              "      <td>0.115646</td>\n",
              "      <td>0.414966</td>\n",
              "      <td>0.598639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.291800</td>\n",
              "      <td>1.099299</td>\n",
              "      <td>1.164177</td>\n",
              "      <td>-2.939466</td>\n",
              "      <td>0.129252</td>\n",
              "      <td>0.482993</td>\n",
              "      <td>0.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.197900</td>\n",
              "      <td>1.071894</td>\n",
              "      <td>1.152017</td>\n",
              "      <td>-3.004821</td>\n",
              "      <td>0.149660</td>\n",
              "      <td>0.448980</td>\n",
              "      <td>0.707483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.158000</td>\n",
              "      <td>1.071362</td>\n",
              "      <td>1.165201</td>\n",
              "      <td>-3.049541</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.469388</td>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 82        |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      | 111396 KiB |  19857 MiB |  37939 GiB |  37939 GiB |\n",
            "|       from large pool |  76217 KiB |  19806 MiB |  37842 GiB |  37842 GiB |\n",
            "|       from small pool |  35179 KiB |     57 MiB |     96 GiB |     96 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         | 111396 KiB |  19857 MiB |  37939 GiB |  37939 GiB |\n",
            "|       from large pool |  76217 KiB |  19806 MiB |  37842 GiB |  37842 GiB |\n",
            "|       from small pool |  35179 KiB |     57 MiB |     96 GiB |     96 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      | 110647 KiB |  19852 MiB |  37906 GiB |  37906 GiB |\n",
            "|       from large pool |  75522 KiB |  19801 MiB |  37809 GiB |  37809 GiB |\n",
            "|       from small pool |  35125 KiB |     57 MiB |     96 GiB |     96 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  16132 MiB |  22440 MiB |   5976 GiB |   5961 GiB |\n",
            "|       from large pool |  16070 MiB |  22378 MiB |   5967 GiB |   5951 GiB |\n",
            "|       from small pool |     62 MiB |     64 MiB |      9 GiB |      9 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory | 398555 KiB |  11248 MiB |  15610 GiB |  15610 GiB |\n",
            "|       from large pool | 386630 KiB |  11239 MiB |  15506 GiB |  15506 GiB |\n",
            "|       from small pool |  11925 KiB |     19 MiB |    104 GiB |    104 GiB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     340    |     559    |    1348 K  |    1347 K  |\n",
            "|       from large pool |      39    |     141    |     631 K  |     631 K  |\n",
            "|       from small pool |     301    |     508    |     716 K  |     716 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     340    |     559    |    1348 K  |    1347 K  |\n",
            "|       from large pool |      39    |     141    |     631 K  |     631 K  |\n",
            "|       from small pool |     301    |     508    |     716 K  |     716 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      65    |      80    |   11431    |   11366    |\n",
            "|       from large pool |      34    |      49    |    6447    |    6413    |\n",
            "|       from small pool |      31    |      32    |    4984    |    4953    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      45    |      94    |  611716    |  611671    |\n",
            "|       from large pool |       7    |      43    |  343210    |  343203    |\n",
            "|       from small pool |      38    |      61    |  268506    |  268468    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/arjan-hada/esm2_t33_650M_UR50D-Ab-CLIP-v0/commit/943b855dedd6c3e11e1a07181e7757b1e6bc9068', commit_message='Training completed!', commit_description='', oid='943b855dedd6c3e11e1a07181e7757b1e6bc9068', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saves the best model\n",
        "trainer.save_model(\"models/esm2_t6_8M_UR50D-Ab-CLIP-v0\")"
      ],
      "metadata": {
        "id": "pgGnVRjLM99X"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_result = trainer.evaluate(eval_dataset=test_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "YFc4m6xMOyLp",
        "outputId": "69a7bc60-5242-4803-d9be-62c885dc39af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [19/19 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results\n",
        "print(f\"Test Loss: {test_result['eval_loss']}\")\n",
        "for key, value in test_result.items():\n",
        "    if key != 'eval_loss':\n",
        "        print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB_IicqAO68l",
        "outputId": "a8d44fa6-a63e-4efe-d453-ee9d3541f6f6"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 0.9265738725662231\n",
            "eval_alignment: 1.0818055868148804\n",
            "eval_uniformity: -3.0300042629241943\n",
            "eval_contrastive_accuracy: 0.18666666746139526\n",
            "eval_top_5_accuracy: 0.5866666436195374\n",
            "eval_top_10_accuracy: 0.753333330154419\n",
            "eval_runtime: 1.4383\n",
            "eval_samples_per_second: 104.29\n",
            "eval_steps_per_second: 13.21\n",
            "epoch: 5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Analysis"
      ],
      "metadata": {
        "id": "r9jcitV9QMhj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided training and evaluation results show the progression of our model's performance across epochs. Here’s a detailed analysis and some insights:\n",
        "\n",
        "\n",
        "\n",
        "**Training Loss and Validation Loss**\n",
        "- **Training Loss**: Decreases steadily from epoch 1 to epoch 5, indicating that the model is learning from the training data.\n",
        "- **Validation Loss**: Decreases initially but stabilizes around epoch 4 and 5. This suggests that the model's ability to generalize to the validation data is not improving significantly after the initial epochs.\n",
        "\n",
        "**Alignment and Uniformity**\n",
        "- **Alignment**: Decreases slightly, which could indicate better matching between the sequence and structure embeddings.\n",
        "- **Uniformity**: Becomes more negative, indicating improved uniformity in the embedding space. This means that embeddings are spread out more evenly, which is generally good for contrastive learning.\n",
        "\n",
        "**Contrastive Accuracy and Top-K Accuracy**\n",
        "- **Contrastive Accuracy**: Shows a gradual improvement but remains relatively low. This metric indicates how well the model is at distinguishing between different sequences and structures.\n",
        "- **Top 5 and Top 10 Accuracy**: Show significant improvement over the epochs. Top-K accuracies are better indicators for retrieval tasks and show that the model is increasingly able to rank the correct pairs higher in the list.\n",
        "\n"
      ],
      "metadata": {
        "id": "sB5aFx3xP7K0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notable Todo for compute_metrics"
      ],
      "metadata": {
        "id": "vqEeTZ7-QgpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In SBERT, embeddings for sentence pairs are used to compute a similarity score, and the embeddings are fine-tuned to improve this similarity measure.\n",
        "\n",
        "1. **Sentence Embeddings**:\n",
        "   - SBERT fine-tunes BERT to derive semantically meaningful sentence embeddings.\n",
        "   - For a given pair of sentences, SBERT computes their [CLS] embeddings.\n",
        "\n",
        "2. **Concatenation and Difference**:\n",
        "   - For a pair of sentences $A$ and $B$, the [CLS] embeddings are obtained as $z_A$ and $z_B$.\n",
        "   - The features used for similarity computation are:\n",
        "     $$\n",
        "     {concat}(z_A, z_B, |z_A - z_B|)\n",
        "     $$\n",
        "   - This concatenated vector is then fed into a regression or classification layer.\n",
        "\n",
        "3. **Regression Head**:\n",
        "   - A simple feed-forward neural network (often with one or two layers) is used to predict the similarity score or to classify the relationship between the sentences.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BYWUHk-0Ic0N"
      }
    }
  ]
}